## About this repository

This repository contains the code for the website of [100 AI Papers with Code(PwC)](https://yuyang.info/100-AI-Papers/)
[![The preview of the website](assets/website.png)](https://yuyang.info/100-AI-Papers/)

Below are list of the papers:
| Paper Name | Code | Blog | Recommendation |
| -------------------------------------------------------------------------------- | --------------------------------------------------------------------------------- | ----------------------------------------------------------------- | --------------- |
| [01 - Attention is All You Need ](https://arxiv.org/abs/1706.03762) (ğŸ‘¾ **Transformer** ğŸ‘¾)| [Code](https://github.com/YYZhang2025/100-AI-Code/blob/main/01-transformer.ipynb) | [Blog](https://yuyang.info/100-AI-Papers/posts/01-attention.html) | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ |
| [02 - An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) (ğŸ‘¾ **Vision Transformer** ğŸ‘¾)| [Code](https://github.com/YYZhang2025/100-AI-Code/blob/main/02_vision_transformer.ipynb) | [Blog](https://yuyang.info/100-AI-Papers/posts/02-vision-transformer.html) | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ |
| [03 - Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030) (ğŸ‘¾ **Swin Transformer** ğŸ‘¾)| [Code](https://github.com/YYZhang2025/100-AI-Code/blob/main/03_swin_transformer.ipynb) | [Blog](https://yuyang.info/100-AI-Papers/posts/03-swin-transformer.html) | â­ï¸â­ï¸â­ï¸ |
| [04 - Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020) (ğŸ‘¾ **CLIP** ğŸ‘¾)| [Code](https://github.com/YYZhang2025/100-AI-Code/blob/main/04_clip.ipynb) | [Blog](https://yuyang.info/100-AI-Papers/posts/04-clip.html) | â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸  |
| [05 - FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/abs/2103.00020) (ğŸ‘¾ **Flash Attention** ğŸ‘¾)| [Code](https://github.com/YYZhang2025/100-AI-Code/blob/main/05_flash_attention.ipynb) | [Blog](https://yuyang.info/100-AI-Papers/posts/05-flash-attention.html) | â­ï¸â­ï¸â­ï¸  |

