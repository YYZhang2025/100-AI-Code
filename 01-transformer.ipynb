{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19bd22f",
   "metadata": {},
   "source": [
    "This is the corresponding code for the [01: Attention is All You Need](https://yyzhang2025.github.io/100-AI-Papers/posts/01-attention.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# DEVICE = get_device()\n",
    "DEVICE = torch.device(\"cpu\")  # Force CPU for debugging\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = \"./tmp/hf_cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b84174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    src_vocab_size: int = 16000\n",
    "    tgt_vocab_size: int = 16000\n",
    "    max_seq: int = 128\n",
    "\n",
    "    d_model: int = 512\n",
    "    d_ff: int = 2048\n",
    "    num_heads: int = 8\n",
    "    num_layers: int = 6\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    eps: float = 1e-6  # for Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96c187f",
   "metadata": {},
   "source": [
    "## Transformer Model Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(nn.Module):\n",
    "    def __init__(self, config: ModelConfig, is_tgt: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        if is_tgt:\n",
    "            self.embedding = nn.Embedding(config.tgt_vocab_size, config.d_model)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(config.src_vocab_size, config.d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        return self.embedding(x)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        pos_index = torch.arange(config.max_seq).unsqueeze(1)  # (max_seq, 1)\n",
    "\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, config.d_model, 2) * -(math.log(10000.0) / config.d_model)\n",
    "        )\n",
    "\n",
    "        pe = torch.zeros(config.max_seq, config.d_model)  # (max_seq, d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos_index * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos_index * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)  # (1, max_seq, d_model)\n",
    "\n",
    "        pe.requires_grad = False\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        return self.pe[:, :seq_len, :]  # (1, seq_len, d_model)\n",
    "\n",
    "\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, config: ModelConfig, is_tgt: bool = False):\n",
    "        super().__init__()\n",
    "        self.word_embedding = WordEmbedding(config, is_tgt)\n",
    "        self.positional_embedding = PositionalEmbedding(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        word_emb = self.word_embedding(x)\n",
    "        pos_emb = self.positional_embedding(word_emb)\n",
    "        return word_emb + pos_emb  # (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ce00f",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "\n",
    "$$\n",
    "\\text{LayerNorm}(x) = \\frac{x - \\mu}{\\sigma + \\epsilon} \\cdot \\gamma + \\beta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.eps = config.eps\n",
    "\n",
    "        self.gamma = nn.Parameter(torch.ones(config.d_model))  # (d_model,)\n",
    "        self.beta = nn.Parameter(torch.zeros(config.d_model))  # (d_model,)\n",
    "\n",
    "    def _compute_mean_std(self, x):\n",
    "        \"\"\"\n",
    "        Compute mean and standard deviation for the input tensor x\n",
    "        On the last dimension (features)\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        Output:\n",
    "            mean: (batch_size, seq_len, 1)\n",
    "            std: (batch_size, seq_len, 1)\n",
    "        \"\"\"\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        # std = x.std(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        std = torch.sqrt(var + self.eps)  # manual epsilon for extra safety\n",
    "        return mean, std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, std = self._compute_mean_std(x)\n",
    "\n",
    "        # print(x.shape, x)\n",
    "        # normalize x: (batch_size, seq_len, d_model)\n",
    "        if torch.isnan(std).any():\n",
    "            print(\"âŒ NaN in LayerNorm std\")\n",
    "            print(\"std min:\", std.min().item(), \"max:\", std.max().item())\n",
    "        normalized_x = (x - mean) / std  # Avoid division by zero\n",
    "\n",
    "        return normalized_x * self.gamma + self.beta  # (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0c8b7",
   "metadata": {},
   "source": [
    "### Feedforward Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf86af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ln1 = nn.Linear(config.d_model, config.d_ff, bias=True)\n",
    "        self.ln2 = nn.Linear(config.d_ff, config.d_model, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.ln1(x))  # Apply ReLU activation\n",
    "        x = self.ln2(x)  # Linear transformation\n",
    "        return x  # (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention\n",
    "    q: (batch_size, num_heads, seq_len_q, d_k)\n",
    "    k: (batch_size, num_heads, seq_len_k, d_k)\n",
    "    v: (batch_size, num_heads, seq_len_v, d_v)\n",
    "    mask: (batch_size, 1, seq_len_q, seq_len_k) or None\n",
    "    \"\"\"\n",
    "    d_k = k.shape[-1]\n",
    "\n",
    "    scores = einops.einsum(\n",
    "        q,\n",
    "        k,\n",
    "        \"batch heads seq_len_q d_k, batch heads seq_len_k d_k -> batch heads seq_len_q seq_len_k\",\n",
    "    )\n",
    "\n",
    "    scores = scores / math.sqrt(d_k)  # Scale the scores\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask, float(\"-inf\"))  # Apply mask if provided\n",
    "\n",
    "    scores = F.softmax(scores, dim=-1)  # Apply softmax to get attention weights\n",
    "\n",
    "    output = einops.einsum(\n",
    "        scores,\n",
    "        v,\n",
    "        \"batch heads seq_len_q seq_len_k, batch heads seq_len_k d_v -> batch heads seq_len_q d_v\",\n",
    "    )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe877cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        assert (\n",
    "            config.d_model % config.num_heads == 0\n",
    "        ), \"d_model must be divisible by num_heads\"\n",
    "        self.d_k = config.d_model // config.num_heads  # Dimension of each head\n",
    "        self.num_heads = config.num_heads\n",
    "\n",
    "        self.qkv_proj = nn.Linear(\n",
    "            config.d_model, config.d_model * 3, bias=True\n",
    "        )  # (d_model, d_model * 3)\n",
    "\n",
    "        self.out_proj = nn.Linear(config.d_model, config.d_model, bias=True)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        mask: (batch_size, 1, seq_len_q, seq_len_k) or None\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        q, k, v = map(\n",
    "            lambda t: einops.rearrange(\n",
    "                t,\n",
    "                \"batch seq_len (heads d_k) -> batch heads seq_len d_k\",\n",
    "                heads=self.num_heads,\n",
    "            ),\n",
    "            self.qkv_proj(x).chunk(3, dim=-1),\n",
    "        )  # (batch, num_heads, seq_len, d_k)\n",
    "\n",
    "        # Compute attention\n",
    "        attn_output = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        # Rearrange back to (batch_size, seq_len, d_model)\n",
    "        attn_output = einops.rearrange(\n",
    "            attn_output,\n",
    "            \"batch heads seq_len d_v -> batch seq_len (heads d_v)\",\n",
    "            heads=self.num_heads,\n",
    "        )\n",
    "\n",
    "        output = self.out_proj(attn_output)  # (batch_size, seq_len, d_model)\n",
    "        return output  # (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3d087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        assert (\n",
    "            config.d_model % config.num_heads == 0\n",
    "        ), \"d_model must be divisible by num_heads\"\n",
    "        self.d_k = config.d_model // config.num_heads  # Dimension of each head\n",
    "\n",
    "        self.num_heads = config.num_heads\n",
    "\n",
    "        self.q_proj = nn.Linear(\n",
    "            config.d_model, config.d_model, bias=True\n",
    "        )  # (d_model, d_model)\n",
    "        self.k_proj = nn.Linear(config.d_model, config.d_model, bias=True)\n",
    "        self.v_proj = nn.Linear(config.d_model, config.d_model, bias=True)\n",
    "        self.out_proj = nn.Linear(config.d_model, config.d_model, bias=True)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        query: (batch_size, seq_len_q, d_model)\n",
    "        key: (batch_size, seq_len_k, d_model)\n",
    "        value: (batch_size, seq_len_v, d_model)\n",
    "        mask: (batch_size, 1, seq_len_q, seq_len_k) or None\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        q = einops.rearrange(\n",
    "            self.q_proj(query),\n",
    "            \"batch seq_len_q (heads d_k) -> batch heads seq_len_q d_k\",\n",
    "            heads=self.num_heads,\n",
    "        )\n",
    "\n",
    "        k = einops.rearrange(\n",
    "            self.k_proj(key),\n",
    "            \"batch seq_len_k (heads d_k) -> batch heads seq_len_k d_k\",\n",
    "            heads=self.num_heads,\n",
    "        )\n",
    "\n",
    "        v = einops.rearrange(\n",
    "            self.v_proj(value),\n",
    "            \"batch seq_len_v (heads d_v) -> batch heads seq_len_v d_v\",\n",
    "            heads=self.num_heads,\n",
    "        )\n",
    "\n",
    "        # Compute attention\n",
    "        attn_output = scaled_dot_product_attention(q, k, v, mask)\n",
    "\n",
    "        # Rearrange back to (batch_size, seq_len_q, d_model)\n",
    "        attn_output = einops.rearrange(\n",
    "            attn_output,\n",
    "            \"batch heads seq_len_q d_v -> batch seq_len_q (heads d_v)\",\n",
    "            heads=self.num_heads,\n",
    "        )\n",
    "\n",
    "        return self.out_proj(attn_output)  # (batch_size, seq_len_q, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a4f10",
   "metadata": {},
   "source": [
    "### Encoder Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(config)\n",
    "        self.ffn = FFN(config)\n",
    "        self.ln1 = LayerNormalization(config)\n",
    "        self.ln2 = LayerNormalization(config)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        out = self.self_attn(x, mask)  # (batch_size, seq_len, d_model)\n",
    "        out = self.ln1(out + x)  # Add & Norm\n",
    "        out = self.ffn(out)  # (batch_size, seq_len, d_model\n",
    "        out = self.ln2(out + x)  # Add & Norm\n",
    "        return out  # (batch_size, seq_len, d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(config)\n",
    "        self.cross_attn = CrossAttention(config)\n",
    "        self.ffn = FFN(config)\n",
    "        self.ln1 = LayerNormalization(config)\n",
    "        self.ln2 = LayerNormalization(config)\n",
    "        self.ln3 = LayerNormalization(config)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        out = self.self_attn(x, tgt_mask)  # Self-attention\n",
    "        out = self.ln1(out + x)  # Add & Norm\n",
    "\n",
    "        out = self.cross_attn(out, enc_output, enc_output, src_mask)  # Cross-attention\n",
    "        out = self.ln2(out + x)  # Add & Norm\n",
    "\n",
    "        out = self.ffn(out)  # Feedforward\n",
    "        out = self.ln3(out + x)  # Add & Norm\n",
    "\n",
    "        return out  # (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = Embedding(config)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [EncoderBlock(config) for _ in range(config.num_layers)]\n",
    "        )\n",
    "        self.ln = LayerNormalization(config)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        x = self.ln(x)  # Final Layer Normalization\n",
    "        return x  # (batch_size, seq_len, d_model)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = Embedding(config, is_tgt=True)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [DecoderBlock(config) for _ in range(config.num_layers)]\n",
    "        )\n",
    "        self.ln = LayerNormalization(config)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len)\n",
    "        enc_output: (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_output, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        x = self.ln(x)  # Final Layer Normalization\n",
    "        return x  # (batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(config)\n",
    "        self.output_layer = nn.Linear(config.d_model, config.tgt_vocab_size)\n",
    "\n",
    "        self._tie_weight()\n",
    "\n",
    "    def _tie_weight(self):\n",
    "        \"\"\"\n",
    "        Tie the weights of the output layer with the embedding layer.\n",
    "        This is a common practice in Transformer models to reduce the number of parameters.\n",
    "        \"\"\"\n",
    "        self.output_layer.weight = (\n",
    "            self.decoder.embedding.word_embedding.embedding.weight\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        src: (batch_size, src_seq_len)\n",
    "        tgt: (batch_size, tgt_seq_len)\n",
    "        mask: (batch_size, 1, tgt_seq_len, src_seq_len) or None\n",
    "        \"\"\"\n",
    "        enc_output = self.encoder(src, src_mask)  # (batch_size, src_seq_len, d_model)\n",
    "        dec_output = self.decoder(\n",
    "            tgt, enc_output, src_mask, tgt_mask\n",
    "        )  # (batch_size, tgt_seq_len, d_model)\n",
    "        output = self.output_layer(\n",
    "            dec_output\n",
    "        )  # (batch_size, tgt_seq_len, tgt_vocab_size)\n",
    "        return output  # Final output logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(seq_len_q, seq_len_k):\n",
    "    \"\"\"\n",
    "    Create a causal mask for the attention mechanism.\n",
    "    seq_len_q: Length of the query sequence\n",
    "    seq_len_k: Length of the key sequence\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(seq_len_q, seq_len_k), diagonal=1).bool()\n",
    "    return mask.unsqueeze(0)  # (1, 1, seq_len_q, seq_len_k)\n",
    "\n",
    "\n",
    "def create_padding_mask(x, padding_idx=0):\n",
    "    \"\"\"\n",
    "    Create a padding mask for the attention mechanism.\n",
    "    seq_len: Length of the sequence\n",
    "    padding_idx: Index used for padding (default is 0)\n",
    "    \"\"\"\n",
    "    mask = (x == padding_idx).unsqueeze(0).unsqueeze(0)  # (1, 1, seq_len)\n",
    "    return mask  # (1, 1, seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(ModelConfig())\n",
    "\n",
    "src = torch.randint(\n",
    "    0, ModelConfig().src_vocab_size, (32, 10)\n",
    ")  # (batch_size, src_seq_len\n",
    "tgt = torch.randint(\n",
    "    0, ModelConfig().tgt_vocab_size, (32, 15)\n",
    ")  # (batch_size, tgt_seq_len\n",
    "\n",
    "causal_mask = create_causal_mask(tgt.size(1), tgt.size(1))\n",
    "output = transformer(src, tgt, tgt_mask=causal_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf69f5",
   "metadata": {},
   "source": [
    "## Dataset Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d125859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# import os\n",
    "\n",
    "\n",
    "# dataset = load_dataset(\n",
    "#     \"iwslt2017\",\n",
    "#     \"iwslt2017-en-zh\",\n",
    "#     download_mode=\"force_redownload\",\n",
    "#     trust_remote_code=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders, processors\n",
    "from tokenizers.normalizers import Sequence, NFKC\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca25f9fd",
   "metadata": {},
   "source": [
    "### Train BPE Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_texts = []\n",
    "# zh_texts = []\n",
    "\n",
    "# for example in dataset[\"train\"]:\n",
    "#     en_texts.append(example[\"translation\"][\"en\"])\n",
    "#     zh_texts.append(example[\"translation\"][\"zh\"])\n",
    "\n",
    "# with open(\"en_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for line in en_texts:\n",
    "#         f.write(line.strip() + \"\\n\")\n",
    "\n",
    "# with open(\"zh_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for line in zh_texts:\n",
    "#         f.write(line.strip() + \"\\n\")\n",
    "\n",
    "\n",
    "def load_or_train_bpe_tokenizer(corpus_file, vocab_size, save_path):\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"Loading tokenizer from {save_path}\")\n",
    "        tokenizer = Tokenizer.from_file(save_path)\n",
    "        return tokenizer\n",
    "    else:\n",
    "        tokenizer = Tokenizer(models.BPE())\n",
    "        tokenizer.normalizer = NFKC()\n",
    "        tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "        trainer = trainers.BpeTrainer(\n",
    "            vocab_size=vocab_size, special_tokens=[\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"]\n",
    "        )\n",
    "\n",
    "        tokenizer.train([corpus_file], trainer)\n",
    "        tokenizer.save(save_path)\n",
    "        print(f\"Saved tokenizer to {save_path}\")\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "\n",
    "en_tokenizer = load_or_train_bpe_tokenizer(\n",
    "    \"en_corpus.txt\", vocab_size=16000, save_path=\"en_bpe.json\"\n",
    ")\n",
    "zh_tokenizer = load_or_train_bpe_tokenizer(\n",
    "    \"zh_corpus.txt\", vocab_size=16000, save_path=\"zh_bpe.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac287e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        raw_dataset,\n",
    "        tokenizer_src,\n",
    "        tokenizer_tgt,\n",
    "        src_lang=\"en\",\n",
    "        tgt_lang=\"ch\",\n",
    "        seq_len=128,\n",
    "    ):\n",
    "        self.ds = raw_dataset\n",
    "        self.tokenizer_src = tokenizer_src\n",
    "        self.tokenizer_tgt = tokenizer_tgt\n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        self.pad_id_src = (\n",
    "            tokenizer_src.token_to_id(\"<pad>\")\n",
    "            if tokenizer_src.token_to_id(\"<pad>\") is not None\n",
    "            else 0\n",
    "        )\n",
    "        self.pad_id_tgt = (\n",
    "            tokenizer_tgt.token_to_id(\"<pad>\")\n",
    "            if tokenizer_tgt.token_to_id(\"<pad>\") is not None\n",
    "            else 0\n",
    "        )\n",
    "        self.sos_id = tokenizer_tgt.token_to_id(\"<s>\") or 1\n",
    "        self.eos_id = tokenizer_tgt.token_to_id(\"</s>\") or 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # item = self.ds[idx][\"translation\"]\n",
    "        item = self.ds[idx]\n",
    "\n",
    "        src_text = item[self.src_lang]\n",
    "        tgt_text = item[self.tgt_lang]\n",
    "\n",
    "        src_ids = self.tokenizer_src.encode(src_text).ids\n",
    "        if len(src_ids) > self.seq_len:\n",
    "            src_ids = src_ids[: self.seq_len]\n",
    "        src_ids = src_ids + [self.pad_id_src] * (self.seq_len - len(src_ids))\n",
    "\n",
    "        tgt_ids = self.tokenizer_tgt.encode(tgt_text).ids\n",
    "        if len(tgt_ids) > self.seq_len - 1:\n",
    "            tgt_ids = tgt_ids[: self.seq_len - 1]\n",
    "        tgt_ids = (\n",
    "            tgt_ids\n",
    "            + [self.eos_id]\n",
    "            + [self.pad_id_tgt] * (self.seq_len - len(tgt_ids) - 1)\n",
    "        )\n",
    "\n",
    "        decoder_ids = self.tokenizer_tgt.encode(tgt_text).ids\n",
    "        if len(decoder_ids) > self.seq_len - 1:\n",
    "            decoder_ids = decoder_ids[: self.seq_len - 1]\n",
    "        decoder_ids = (\n",
    "            [self.sos_id]\n",
    "            + decoder_ids\n",
    "            + [self.pad_id_tgt] * (self.seq_len - len(decoder_ids) - 1)\n",
    "        )\n",
    "\n",
    "        src_ids = torch.tensor(src_ids, dtype=torch.int64)\n",
    "        tgt_ids = torch.tensor(tgt_ids, dtype=torch.int64)\n",
    "        decoder_ids = torch.tensor(decoder_ids, dtype=torch.int64)\n",
    "\n",
    "        assert decoder_ids.size(0) == self.seq_len\n",
    "        assert tgt_ids.size(0) == self.seq_len\n",
    "        assert src_ids.size(0) == self.seq_len\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": src_ids,\n",
    "            \"labels\": tgt_ids,\n",
    "            \"decoder_input_ids\": decoder_ids,\n",
    "            \"encoder_mask\": create_padding_mask(src_ids, self.pad_id_src),\n",
    "            \"decoder_mask\": create_causal_mask(decoder_ids.size(0), decoder_ids.size(0))\n",
    "            & create_padding_mask(decoder_ids, self.pad_id_tgt),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b29177",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][:1000][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25cac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zh_tokenizer = Tokenizer.from_file(\"zh_bpe.json\")\n",
    "# en_tokenizer = Tokenizer.from_file(\"en_bpe.json\")\n",
    "\n",
    "\n",
    "translation_dataset = TranslationDataset(\n",
    "    # raw_dataset=dataset[\"train\"],\n",
    "    raw_dataset=dataset[\"train\"][:1000][\"translation\"],\n",
    "    tokenizer_src=zh_tokenizer,\n",
    "    tokenizer_tgt=en_tokenizer,\n",
    "    src_lang=\"zh\",\n",
    "    tgt_lang=\"en\",\n",
    "    seq_len=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = translation_dataset[0]\n",
    "\n",
    "input_ids = sample[\"input_ids\"]\n",
    "decoder_input_ids = sample[\"decoder_input_ids\"]\n",
    "labels = sample[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44121b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zh_tokenizer.decode(input_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d70ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer.decode(decoder_input_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36108c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer.decode(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3544407",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    translation_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a60e9b",
   "metadata": {},
   "source": [
    "## Training Procedure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb763ae",
   "metadata": {},
   "source": [
    "### Loss Function with Label Smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, config: ModelConfig, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "        self.vocab_size = config.tgt_vocab_size\n",
    "        self.eps = smoothing / (self.vocab_size - 1)\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        logits: (batch_size, seq_len, vocab_size)\n",
    "        target: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        log_probs = F.log_softmax(logits, dim=-1)  # (batch_size, seq_len, vocab_size)\n",
    "        nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        smooth_loss = -log_probs.mean(dim=-1)  # Average over vocabulary\n",
    "        loss = (1.0 - self.smoothing) * nll_loss + self.eps * smooth_loss\n",
    "\n",
    "        return loss.mean()  # Average over batch and sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLossWithLabelSmoothing(nn.Module):\n",
    "    def __init__(self, config: ModelConfig, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.label_smoothing = LabelSmoothing(config, smoothing)\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        \"\"\"\n",
    "        logits: (batch_size, seq_len, vocab_size)\n",
    "        target: (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        return self.label_smoothing(logits, target)  # Compute loss with label smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aefb43",
   "metadata": {},
   "source": [
    "### Adam Optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc84b4bc",
   "metadata": {},
   "source": [
    "$$\\theta_{t+1} = \\theta_t - \\eta \\cdot \\frac{m_{t,i}}{\\sqrt{v_{t,i}}+\\epsilon}$$\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{m}*{t,i} &= \\frac{m*{t,i}}{1-\\beta*1^t} \\\\\n",
    "\\hat{v}_{t,i} &= \\frac{v\\_{t,i}}{1-\\beta_2^t}\n",
    "\\end{align_}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, model_params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8):\n",
    "        self.model_params = list(model_params)\n",
    "        self.lr = lr\n",
    "        self.beta_1, self.beta_2 = betas\n",
    "        self.eps = eps\n",
    "        self.avg_grads = [torch.zeros_like(p) for p in self.model_params]\n",
    "        self.avg_squares = [torch.zeros_like(p) for p in self.model_params]\n",
    "        self.n_steps = 0\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.model_params:\n",
    "            p.grad = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        self.n_steps += 1  # increment ONCE per step\n",
    "\n",
    "        for p, m, v in zip(self.model_params, self.avg_grads, self.avg_squares):\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "\n",
    "            # Update moving averages\n",
    "            m.mul_(self.beta_1).add_(p.grad, alpha=1 - self.beta_1)\n",
    "            v.mul_(self.beta_2).addcmul_(p.grad, p.grad, value=1 - self.beta_2)\n",
    "\n",
    "            # Bias correction\n",
    "            m_hat = m / (1 - self.beta_1**self.n_steps)\n",
    "            v_hat = v / (1 - self.beta_2**self.n_steps)\n",
    "\n",
    "            # Parameter update\n",
    "            p.addcdiv_(m_hat, v_hat.sqrt() + self.eps, value=-self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1830eb95",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e1052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    data,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input_ids = data[\"input_ids\"].to(DEVICE)\n",
    "    decoder_input_ids = data[\"decoder_input_ids\"].to(DEVICE)\n",
    "    enc_mask = data[\"encoder_mask\"].to(DEVICE)\n",
    "    dec_mask = data[\"decoder_mask\"].to(DEVICE)\n",
    "\n",
    "    labels = data[\"labels\"].to(DEVICE)\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(input_ids, decoder_input_ids, src_mask=enc_mask, tgt_mask=dec_mask)\n",
    "    print(torch.isnan(logits).any(), torch.isinf(logits).any())\n",
    "    # print(\"logits NaN:\", torch.isnan(logits).any())\n",
    "    # print(\"logits max:\", torch.nanmax(logits).item())\n",
    "    # print(\"logits min:\", torch.nanmin(logits).item())\n",
    "\n",
    "    # Compute loss # Debugging line\n",
    "    loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "\n",
    "    # Backward pass\n",
    "    # loss.backward()\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()  # Return the loss value for logging\n",
    "\n",
    "\n",
    "def train(model, dataset, optimizer, criterion, num_epochs=10, batch_size=32):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(dataset, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            loss = train_step(model, optimizer, criterion, batch)\n",
    "            total_loss += loss\n",
    "\n",
    "        avg_loss = total_loss / (len(dataset) // batch_size)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4642be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "model = Transformer(ModelConfig()).to(DEVICE)\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "# criterion = CrossEntropyLossWithLabelSmoothing(ModelConfig(), smoothing=0.1)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(\n",
    "    DEVICE\n",
    ")  # Use standard CrossEntropyLoss with padding index\n",
    "\n",
    "# Train the model\n",
    "train(model, train_dataloader, optimizer, criterion, num_epochs=10, batch_size=32)\n",
    "# Initialize model, optimizer, and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72bfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43793982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf844106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e47f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
